{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1357a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1'). \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config('spark.sql.warehouse.dir', f'/user/{username}/warehouse'). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Kafka and Spark Integration'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c49271c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_bootstrap_servers = 'w01.itversity.com:9092,w02.itversity.com:9092'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b01f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark. \\\n",
    "  readStream. \\\n",
    "  format('kafka'). \\\n",
    "  option('kafka.bootstrap.servers', kafka_bootstrap_servers). \\\n",
    "  option('subscribe', f'{username}_retail'). \\\n",
    "  load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9bf3bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2597012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, date_format, to_date, split, substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d18f4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [('X',)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57d66595",
   "metadata": {},
   "outputs": [],
   "source": [
    "dual = spark.createDataFrame(l, schema='dummy STRING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "036d4f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+\n",
      "|to_date('2021-Jan-21', 'yyyy-MMM-dd')|\n",
      "+-------------------------------------+\n",
      "|                           2021-01-21|\n",
      "+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dual.select(to_date(lit('2021-Jan-21'), 'yyyy-MMM-dd')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daedc439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+\n",
      "|to_date('31/Dec/2021:00:37:39', 'dd/MMM/yyyy:HH:mm:ss')|\n",
      "+-------------------------------------------------------+\n",
      "|                                             2021-12-31|\n",
      "+-------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dual.select(to_date(lit('31/Dec/2021:00:37:39'), 'dd/MMM/yyyy:HH:mm:ss')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e258dce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7fa48af6c240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\"). \\\n",
    "    writeStream. \\\n",
    "    format(\"console\"). \\\n",
    "    option('truncate', 'false'). \\\n",
    "    trigger(processingTime='5 seconds'). \\\n",
    "    start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\"). \\\n",
    "    withColumn('year', date_format(to_date(split('value', ' ')[3], '[dd/MMM/yyyy:HH:mm:ss'), 'yyyy')). \\\n",
    "    withColumn('month', date_format(to_date(split('value', ' ')[3], '[dd/MMM/yyyy:HH:mm:ss'), 'MM')). \\\n",
    "    withColumn('dayofmonth', date_format(to_date(split('value', ' ')[3], '[dd/MMM/yyyy:HH:mm:ss'), 'dd')). \\\n",
    "    writeStream. \\\n",
    "    format(\"console\"). \\\n",
    "    option('truncate', 'false'). \\\n",
    "    trigger(processingTime='5 seconds'). \\\n",
    "    start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa524cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7fa48af6cbe0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\"). \\\n",
    "    withColumn('log_date', to_date(substring(split('value', ' ')[3], 2, 21), '[dd/MMM/yyyy:HH:mm:ss')). \\\n",
    "    withColumn('year', date_format('log_date', 'yyyy')). \\\n",
    "    withColumn('month', date_format('log_date', 'MM')). \\\n",
    "    withColumn('dayofmonth', date_format('log_date', 'dd')). \\\n",
    "    writeStream. \\\n",
    "    format(\"memory\"). \\\n",
    "    queryName(\"log_messages\"). \\\n",
    "    start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dcb2b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+----+-----+----------+\n",
      "|key |value                                                                                                                                                                                                                                      |log_date  |year|month|dayofmonth|\n",
      "+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+----+-----+----------+\n",
      "|null|148.168.116.252 - - [22/Aug/2021:13:48:58 -0800] \"GET /departments HTTP/1.1\" 200 1192 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko\"                                                                           |2021-08-22|2021|08   |22        |\n",
      "|null|199.189.163.133 - - [22/Aug/2021:13:48:59 -0800] \"GET /department/team%20sports/categories HTTP/1.1\" 200 273 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36\"|2021-08-22|2021|08   |22        |\n",
      "+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+----+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM log_messages').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ba9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('SELECT count(1) FROM log_messages').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd558727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
