{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5071bd98",
   "metadata": {},
   "source": [
    "## Writing Streaming Data to Files\n",
    "\n",
    "As we have successfully read the data and see it is being processed using `writeStream.format('console')`, now it is time for us to understand how the data can be written to files.\n",
    "\n",
    "Here are the steps we need to follow to write the data to files:\n",
    "1. Ensure the logs are being redirected to Netcat Webserver\n",
    "2. Read the data using `spark.readStream` with `format('socket')`\n",
    "3. Use `writeStream.format` with appropriate options related to the file format. We will be using `writeStream.format('csv')` and hence we need to specify checkpoint and target location.\n",
    "```\n",
    "socketDF \\\n",
    "    .writeStream \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"checkpointLocation\", \"/FileStore/retail_logs/gen_logs/checkpoint\") \\\n",
    "    .option(\"path\", \"/FileStore/retail_logs/gen_logs/data\") \\\n",
    "    .start()\n",
    "```\n",
    "4. Validate both the checkpoint location as well as data location in which files are being copied to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db17962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Overview of Structured Streaming'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b138b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "socketDF = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"socket\") \\\n",
    "    .option(\"host\", \"localhost\") \\\n",
    "    .option(\"port\", 9000) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5180f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "socketDF \\\n",
    "    .writeStream \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"path\", \"/FileStore/retail_logs/gen_logs/data\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9defd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "socketDF \\\n",
    "  .writeStream \\\n",
    "  .format(\"csv\") \\\n",
    "  .option(\"checkpointLocation\", \"/FileStore/retail_logs/gen_logs/checkpoint\") \\\n",
    "  .option(\"path\", \"/FileStore/retail_logs/gen_logs/data\") \\\n",
    "  .trigger(processingTime='5 seconds') \\\n",
    "  .start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
