{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Kafka Connect to produce messages\n",
    "\n",
    "Let's prepare Kafka Connect properties files so that data can be produced into the Kafka Topic using Kafka Connect.\n",
    "\n",
    "* Make sure there is a topic in which we can generate data.\n",
    "\n",
    "```shell\n",
    "kafka-topics.sh \\\n",
    "  --zookeeper m01.itversity.com:2181,m02.itversity.com:2181,r01.itversity.com:2181 \\\n",
    "  --create \\\n",
    "  --topic `whoami`_retail \\\n",
    "  --replication-factor 2 \\\n",
    "  --partitions 3\n",
    "```\n",
    "\n",
    "* Create a working folder - **~/kafka_connect/produce_demo**\n",
    "\n",
    "```shell\n",
    "mkdir -p ~/kafka_connect/retail_logs_produce\n",
    "cd ~/kafka_connect/retail_logs_produce\n",
    "```\n",
    "\n",
    "* Copy following files from Kafka config folder.\n",
    "  * connect-standalone.properties\n",
    "  * connect-file-source.properties\n",
    "\n",
    "```shell\n",
    "cp /opt/kafka/config/connect-standalone.properties \\\n",
    "    ~/kafka_connect/retail_logs_produce/retail_logs_standalone.properties\n",
    "cp /opt/kafka/config/connect-file-source.properties \\\n",
    "    ~/kafka_connect/retail_logs_produce/retail_logs_file_source.properties\n",
    "```\n",
    "\n",
    "* Update **retail_logs_standalone.properties** \n",
    "  * Bootstrap servers with more than one brokers on multinode cluster.\n",
    "  * Key and Value Converters\n",
    "  * Offset file name\n",
    "\n",
    "```shell\n",
    "bootstrap.servers=w01.itversity.com:9092,w02.itversity.com:9092\n",
    "\n",
    "key.converter=org.apache.kafka.connect.storage.StringConverter\n",
    "value.converter=org.apache.kafka.connect.storage.StringConverter\n",
    "\n",
    "key.converter.schemas.enable=true\n",
    "value.converter.schemas.enable=true\n",
    "\n",
    "offset.storage.file.filename=/home/itversity/kafka_connect/retail_logs_produce/retail.offsets\n",
    "# Flush much faster than normal, which is useful for testing/debugging\n",
    "offset.flush.interval.ms=10000\n",
    "```\n",
    "\n",
    "* Update **retail_logs_file_source.properties**\n",
    "  * Location of the file\n",
    "  * Topic Name\n",
    "\n",
    "```shell\n",
    "name=local-file-source\n",
    "connector.class=FileStreamSource\n",
    "tasks.max=1\n",
    "file=/opt/gen_logs/logs/access.log\n",
    "topic=${USER}_retail\n",
    "```\n",
    "\n",
    "* We will validate as part of the next topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
